{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn import set_config\n",
    "\n",
    "from sksurv.datasets import load_flchain, load_gbsg2\n",
    "from sksurv.functions import StepFunction\n",
    "from sksurv.ensemble import RandomSurvivalForest, GradientBoostingSurvivalAnalysis\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "from sksurv.metrics import as_concordance_index_ipcw_scorer\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sksurv.preprocessing import OneHotEncoder, encode_categorical\n",
    "from sksurv.util import Surv\n",
    "\n",
    "import scipy.optimize as opt\n",
    "\n",
    "set_config(display=\"text\")  \n",
    "plt.rcParams[\"figure.figsize\"] = [7.2, 4.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_marker(n_samples, m,  baseline_hazard, rnd, time_points=None):\n",
    "    \n",
    "    # create synthetic risk scores with uniform distribution\n",
    "    X = np.array(rnd.uniform(low=-1.0, high = 1.0, size=(n_samples, m)))\n",
    "    hazard_ratio = np.expand_dims(np.array(rnd.uniform(low = 0, high = 0.1, size=m)), axis=0)\n",
    "    coef = np.log(hazard_ratio)\n",
    "\n",
    "    # create linear model\n",
    "    logits = np.dot(X, coef.T)\n",
    "\n",
    "    # draw actual survival times from exponential distribution,\n",
    "    # refer to Bender et al. (2005), https://doi.org/10.1002/sim.2059\n",
    "    u = rnd.uniform(size=n_samples)\n",
    "    risk_scores = np.squeeze(logits)\n",
    "    time_event = -np.log(u) / (baseline_hazard * np.exp(risk_scores))\n",
    "\n",
    "    # calculate actual concordance (with no censoring)\n",
    "    actual = concordance_index_censored(np.ones(n_samples, dtype=bool), time_event, risk_scores)\n",
    "\n",
    "    # calculate baseline AUC (with no censoring)\n",
    "    y_uncensored = np.array([(True, t) for t in time_event], \n",
    "                  dtype=[('event', bool), ('time', float)])\n",
    "    \n",
    "    baseline_auc, baseline_mean_auc = cumulative_dynamic_auc(\n",
    "        y_uncensored, y_uncensored, risk_scores, time_points\n",
    "    )\n",
    "\n",
    "    return X, time_event, actual[0], hazard_ratio, risk_scores, baseline_auc, baseline_mean_auc, time_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_survival_data(n_samples, m, baseline_hazard, percentage_cens, rnd, time_points=None, retry=True, evaluate_auc=True):\n",
    "                 \n",
    "    X, time_event, actual_c, hazard_ratio, risk_scores, baseline_auc, baseline_mean_auc, eval_time_points = generate_marker(\n",
    "        n_samples, m, baseline_hazard, rnd, time_points)\n",
    "\n",
    "    def get_observed_time(x): # this censors certain time events\n",
    "        rnd_cens = rnd\n",
    "        # draw censoring times\n",
    "        time_censor = rnd_cens.uniform(high=x, size=n_samples)\n",
    "        event = time_event < time_censor\n",
    "        time = np.where(event, time_event, time_censor)\n",
    "        return event, time # returns bool array of if event occured or not/censored, and the time it occured/ was censored\n",
    "\n",
    "    def censoring_amount(x): # finds optimal time event for censoring to be as close to desired censored amount\n",
    "        event, _ = get_observed_time(x)\n",
    "        cens = 1.0 - event.sum() / event.shape[0]\n",
    "        return (cens - percentage_cens) ** 2\n",
    "\n",
    "    # search for upper limit to obtain the desired censoring amount\n",
    "    res = opt.minimize_scalar(censoring_amount, method=\"bounded\", bounds=(0, time_event.max()))\n",
    "\n",
    "    if ( np.abs(res.fun) > 2.0/n_samples and retry): # check for convergence\n",
    "        return generate_survival_data(n_samples, m, baseline_hazard, percentage_cens, rnd=rnd, retry=False, time_points=time_points)\n",
    "    elif (np.abs(res.fun) > 2.0/n_samples and not retry):\n",
    "        converged = False\n",
    "    else:\n",
    "        converged = True\n",
    "\n",
    "    # compute observed time\n",
    "    event, time = get_observed_time(res.x) # now that we have the optimal time event, we use that to get all the events and times\n",
    "\n",
    "    # tau limits the data we look at. Here we are keeping events where time is < latest observed event time. (This decrease biases)\n",
    "    tau = time[event].max()\n",
    "    y = Surv.from_arrays(event=event, time=time)\n",
    "    mask = time < tau\n",
    "    X_test = X[mask]\n",
    "    y_test = y[mask]\n",
    "\n",
    "    return X_test, y_test, y, actual_c, converged, hazard_ratio, risk_scores[mask], baseline_mean_auc, eval_time_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(n_samples, m, n_repeats=100, time_points=10, use_gridsearch=True):\n",
    "\n",
    "    rnd = np.random.RandomState(42) \n",
    "    \n",
    "    measures = (\n",
    "        \"censoring\",\n",
    "        \"Actual C\",\n",
    "        \"Harrel's C\",\n",
    "        \"Uno's C\",\n",
    "        \"Baseline AUC\",\n",
    "        \"AUC\",\n",
    "        \"Brier\",\n",
    "    )\n",
    "    results = {\n",
    "        \"rsf\": {\"mean\": [], \"std\": [], \"censoring\": []},    \n",
    "    }\n",
    "    \n",
    "    # hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'min_samples_split': [5, 10, 20],\n",
    "        'min_samples_leaf': [5, 10, 15],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'max_depth': [3, 5, 7, None]\n",
    "    }\n",
    "    \n",
    "    best_params_per_censoring = {}\n",
    "    \n",
    "    # iterate over different amount of censoring\n",
    "    for cens in [0, 0.25, 0.5]:\n",
    "        data = {\n",
    "            \"rsf\": {measure: [] for measure in measures},\n",
    "        }\n",
    "\n",
    "        # perform grid search once per censoring level (not per repeat)\n",
    "        if use_gridsearch:\n",
    "            print(f\"Running GridSearch for censoring level {cens}\")\n",
    "            \n",
    "            # Generate a representative dataset for grid search\n",
    "            X_grid, y_grid, _, _, _, _, _, _, _ = generate_survival_data(\n",
    "                n_samples, m, baseline_hazard=0.1, percentage_cens=cens, rnd=rnd, time_points=time_points\n",
    "            )\n",
    "\n",
    "            base_model = RandomSurvivalForest(random_state=rnd, n_jobs=1)\n",
    "            scorer = as_concordance_index_ipcw_scorer(base_model)\n",
    "\n",
    "                     \n",
    "            cv = KFold(n_splits=3, shuffle=True, random_state=rnd)\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=scorer,  \n",
    "                param_grid={'estimator__' + k: v for k, v in param_grid.items()},  # Prefix with 'estimator__'\n",
    "                cv=cv,\n",
    "                n_jobs=-1,\n",
    "                verbose=1,\n",
    "                error_score='raise'\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                grid_search.fit(X_grid, y_grid)\n",
    "                \n",
    "                best_params = {k.replace('estimator__', ''): v \n",
    "                             for k, v in grid_search.best_params_.items()}\n",
    "                best_params_per_censoring[cens] = best_params\n",
    "                \n",
    "                print(f\"Best parameters for censoring {cens}: {best_params}\")\n",
    "                print(f\"Best CV score: {grid_search.best_score_:.3f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"GridSearch failed for censoring {cens}: {str(e)}\")\n",
    "                # default parameters\n",
    "                best_params_per_censoring[cens] = {\n",
    "                    'n_estimators': 100,\n",
    "                    'min_samples_split': 10,\n",
    "                    'min_samples_leaf': 15,\n",
    "                    'max_features': 'sqrt',\n",
    "                    'max_depth': None\n",
    "                }\n",
    "        else:\n",
    "            # default parameters if grid search is disabled\n",
    "            best_params_per_censoring[cens] = {\n",
    "                'n_estimators': 100,\n",
    "                'min_samples_split': 10,\n",
    "                'min_samples_leaf': 15,\n",
    "                'max_features': 'sqrt',\n",
    "                'max_depth': None\n",
    "            }\n",
    "\n",
    "        # Now perform repeated simulations with the best parameters\n",
    "        for repeat_idx in range(n_repeats):\n",
    "            \n",
    "            X_test, y_test, y_train, actual_c, converged, hazard_ratio, true_risk_scores, baseline_mean_auc, eval_time_points = generate_survival_data(\n",
    "                n_samples, m, baseline_hazard=0.1, percentage_cens=cens, rnd=rnd, time_points=time_points\n",
    "            )\n",
    "        \n",
    "            if not converged:\n",
    "                continue  # Skip this repeat if convergence failed\n",
    "\n",
    "            for model_type in [\"rsf\"]:\n",
    "                # Use the best parameters found for this censoring level\n",
    "                best_params = best_params_per_censoring[cens]\n",
    "                \n",
    "                # Create model with best parameters\n",
    "                model = RandomSurvivalForest(\n",
    "                    random_state=rnd,\n",
    "                    n_jobs=-1,\n",
    "                    **best_params\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    model.fit(X_test, y_test)\n",
    "                except Exception as e:\n",
    "                    print(f\"Model fitting failed for repeat {repeat_idx+1}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "                # predict risk scores \n",
    "                risk_scores = model.predict(X_test)\n",
    "                \n",
    "                # Generate time points for evaluation\n",
    "                times = np.linspace(y_test[\"time\"].min() + 0.001, y_test[\"time\"].max() - 0.001, time_points)\n",
    "\n",
    "                # Compute cumulative dynamic AUC\n",
    "                try:\n",
    "                    aucs, _ = cumulative_dynamic_auc(y_train, y_test, risk_scores, times)\n",
    "                    mean_auc = np.nanmean(aucs)\n",
    "                except Exception as e:\n",
    "                    print(f\"AUC calculation failed: {e}\")\n",
    "                    mean_auc = np.nan\n",
    "\n",
    "                # Brier Score - requires survival function predictions\n",
    "                try:\n",
    "                    pred_func = model.predict_survival_function(X_test)\n",
    "                    preds = np.asarray([[fn(t) for t in times] for fn in pred_func])\n",
    "                    brier = integrated_brier_score(y_train, y_test, preds, times)\n",
    "                except Exception as e:\n",
    "                    print(f\"Brier score calculation failed: {e}\")\n",
    "                    brier = np.nan\n",
    "\n",
    "                # Estimate c-indices\n",
    "                try:\n",
    "                    c_actual = actual_c\n",
    "                    c_harrell = concordance_index_censored(y_test[\"event\"], y_test[\"time\"], risk_scores)\n",
    "                    c_uno = concordance_index_ipcw(y_train, y_test, risk_scores)\n",
    "                    \n",
    "                    # Calculate actual censoring percentage\n",
    "                    censoring_pct = (1 - y_test[\"event\"].sum() / y_test.shape[0]) * 100.0\n",
    "                    \n",
    "                    # Save results\n",
    "                    data[model_type][\"censoring\"].append(censoring_pct)\n",
    "                    data[model_type][\"Actual C\"].append(c_actual)\n",
    "                    data[model_type][\"Harrel's C\"].append(c_harrell[0])\n",
    "                    data[model_type][\"Uno's C\"].append(c_uno[0])\n",
    "                    data[model_type][\"Baseline AUC\"].append(baseline_mean_auc)\n",
    "                    data[model_type][\"AUC\"].append(mean_auc)\n",
    "                    data[model_type][\"Brier\"].append(brier)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Metric calculation failed: {e}\")\n",
    "                    continue\n",
    "\n",
    "        # Aggregate results for this censoring level\n",
    "        for model_type in [\"rsf\"]:\n",
    "            data_mean = {key: [np.mean(value)] for key, value in data[model_type].items()}\n",
    "            data_std = {key: [np.std(value, ddof=1)] for key, value in data[model_type].items()}\n",
    "\n",
    "            results[model_type][\"mean\"].append(pd.DataFrame(data_mean))\n",
    "            results[model_type][\"std\"].append(pd.DataFrame(data_std))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, model_type=\"rsf\", **kwargs):\n",
    "    \n",
    "    # Concatenate DataFrames from the list of results\n",
    "    data_mean = pd.concat(results[model_type][\"mean\"])\n",
    "    data_std = pd.concat(results[model_type][\"std\"])\n",
    "    \n",
    "    # Create index based on censoring values\n",
    "    index = pd.Index(data_mean[\"censoring\"].round(3), name=\"mean percentage censoring\")\n",
    "    for df in (data_mean, data_std):\n",
    "        df.drop(\"censoring\", axis=1, inplace=True)\n",
    "        df.index = index\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6), sharex=True)\n",
    "    \n",
    "    # Concordance indexes plot\n",
    "    cindex_columns = [\"Actual C\", \"Harrel's C\", \"Uno's C\"]\n",
    "    data_mean_cindex = data_mean[cindex_columns]\n",
    "    data_std_cindex = data_std[cindex_columns]\n",
    "    \n",
    "    # Plot the bar chart for concordance indexes\n",
    "    data_mean_cindex.plot.bar(\n",
    "        yerr=data_std_cindex,\n",
    "        ax=axes[0],\n",
    "        width=0.7,\n",
    "        linewidth=0.5,\n",
    "        capsize=4,\n",
    "        **kwargs\n",
    "    )\n",
    "    axes[0].set_ylabel(\"Concordance\")\n",
    "    axes[0].set_title(\"Concordance Index Errors\")\n",
    "    axes[0].yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "    axes[0].set_ylim(0, 1)  # Set y-axis limit to match the image\n",
    "    axes[0].axhline(0.0, color=\"gray\", linewidth=0.8)\n",
    "    \n",
    "    # AUC comparison plot (Baseline vs Model)\n",
    "    auc_columns = [\"Baseline AUC\", \"AUC\"]\n",
    "    data_mean_auc = data_mean[auc_columns]\n",
    "    data_std_auc = data_std[auc_columns]\n",
    "    \n",
    "    # Plot the bar chart for AUC comparison\n",
    "    data_mean_auc.plot.bar(\n",
    "        yerr=data_std_auc,\n",
    "        ax=axes[1],\n",
    "        width=0.7,\n",
    "        linewidth=0.5,\n",
    "        capsize=4,\n",
    "        **kwargs\n",
    "    )\n",
    "    axes[1].set_ylabel(\"AUC Score\")\n",
    "    axes[1].set_title(\"AUC Comparison: Baseline vs Model\")\n",
    "    axes[1].yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "    axes[1].set_ylim(0, 1.0)\n",
    "    \n",
    "    # Brier score plot\n",
    "    brier_column = [\"Brier\"]\n",
    "    data_mean_brier = data_mean[brier_column]\n",
    "    data_std_brier = data_std[brier_column]\n",
    "    \n",
    "    # Plot the bar chart for Brier scores\n",
    "    data_mean_brier.plot.bar(\n",
    "        yerr=data_std_brier,\n",
    "        ax=axes[2],\n",
    "        width=0.7,\n",
    "        linewidth=0.5,\n",
    "        capsize=4,\n",
    "        **kwargs\n",
    "    )\n",
    "    axes[2].set_ylabel(\"Brier Score\")\n",
    "    axes[2].set_title(\"Integrated Brier Score\")\n",
    "    axes[2].yaxis.grid(True, linestyle='--', alpha=0.7)\n",
    "    axes[2].set_ylim(0, 0.5)  # Brier scores are typically lower, adjust as needed\n",
    "    \n",
    "    # x-axis label on the bottom plot\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(\"Mean Percentage Censoring\")\n",
    "    \n",
    "    # Remove top and right spines for all axes\n",
    "    for ax in axes:\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.tick_params(axis='x', labelrotation=90)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearch for censoring level 0\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "GridSearch failed for censoring 0: censoring survival function is zero at one or more time points\n",
      "Running GridSearch for censoring level 0.25\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Best parameters for censoring 0.25: {'max_depth': None, 'max_features': None, 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best CV score: 0.907\n",
      "Running GridSearch for censoring level 0.5\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "GridSearch failed for censoring 0.5: censoring survival function is zero at one or more time points\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "results = simulation(n_samples=1000, m=3, n_repeats=5, time_points=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
